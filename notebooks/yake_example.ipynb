{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1065e954-439f-4dbe-b305-9e465781ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Name: yake\n",
      "Version: 0.6.0\n",
      "Summary: Keyword extraction Python package\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Arian Pasquali <arianpasquali@gmail.com>, Ricadro Campos <ricardo.campos@ubi.pt>, Tiago Vaente <tiago.leando.valente@ubi.com>\n",
      "License: LGPLv3\n",
      "Location: /opt/anaconda3/lib/python3.12/site-packages\n",
      "Requires: click, jellyfish, networkx, numpy, segtok, tabulate\n",
      "Required-by: \n",
      "Collecting git+https://github.com/LIAAD/yake.git\n",
      "  Cloning https://github.com/LIAAD/yake.git to /private/var/folders/gs/rm1mjp5x5ybc93h8m4xwbfyr0000gn/T/pip-req-build-egek8plh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/LIAAD/yake.git /private/var/folders/gs/rm1mjp5x5ybc93h8m4xwbfyr0000gn/T/pip-req-build-egek8plh\n",
      "  Resolved https://github.com/LIAAD/yake.git to commit 6f726586608896d3f5dee8d73e1a168fc9416176\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click>=6.0 in /opt/anaconda3/lib/python3.12/site-packages (from yake==0.6.0) (8.1.7)\n",
      "Requirement already satisfied: jellyfish in /opt/anaconda3/lib/python3.12/site-packages (from yake==0.6.0) (1.0.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from yake==0.6.0) (3.3)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /opt/anaconda3/lib/python3.12/site-packages (from yake==0.6.0) (1.26.4)\n",
      "Requirement already satisfied: segtok in /opt/anaconda3/lib/python3.12/site-packages (from yake==0.6.0) (1.5.11)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.12/site-packages (from yake==0.6.0) (0.9.0)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.12/site-packages (from segtok->yake==0.6.0) (2024.9.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk\n",
    "!pip show yake\n",
    "!pip install --upgrade git+https://github.com/LIAAD/yake.git\n",
    "\n",
    "import yake\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2c645f-0e1a-4da7-8a8f-dd2cc61d64b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google (0.026580863364597897)\n",
      "Kaggle (0.0289005976239829)\n",
      "CEO Anthony Goldbloom (0.029946071606210194)\n",
      "San Francisco (0.048810837074825336)\n",
      "Anthony Goldbloom declined (0.06176910090701819)\n",
      "Google Cloud Platform (0.06261974476422487)\n",
      "co-founder CEO Anthony (0.07357749587020043)\n",
      "acquiring Kaggle (0.08723571551039863)\n",
      "CEO Anthony (0.08915156857226395)\n",
      "Anthony Goldbloom (0.09123482372372106)\n",
      "machine learning (0.09147989238151344)\n",
      "Kaggle co-founder CEO (0.093805063905847)\n",
      "data (0.097574333771058)\n",
      "Google Cloud (0.10260128641464673)\n",
      "machine learning competitions (0.10773000650607861)\n",
      "Francisco this week (0.11519915079240485)\n",
      "platform (0.1183512305596321)\n",
      "conference in San (0.12392066376108138)\n",
      "service (0.12546743261462942)\n",
      "Goldbloom (0.14611408778815776)\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "\n",
    "text = \"Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud Next conference in San Francisco this week, the official announcement could come as early as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. Google itself declined 'to comment on rumors'. Kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom  and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). Kaggle has a bit of a history with Google, too, but that's pretty recent. Earlier this month, Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle's community than technology, Kaggle did build some interesting tools for hosting its competition and 'kernels', too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them 'scripts'). Like similar competition-centric sites, Kaggle also runs a job board, too. It's unclear what Google will do with that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it's $12.75) since its   launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, Google chief economist Hal Varian, Khosla Ventures and Yuri Milner \"\n",
    "\n",
    "# Simple usage with default parameters\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "\n",
    "for kw, score in keywords:\n",
    "    print(f\"{kw} ({score})\")\n",
    "\n",
    "# With custom parameters\n",
    "custom_kw_extractor = yake.KeywordExtractor(\n",
    "    lan=\"en\",              # language\n",
    "    n=3,                   # ngram size\n",
    "    dedupLim=0.9,          # deduplication threshold\n",
    "    dedupFunc='seqm',      # deduplication function\n",
    "    windowsSize=1,         # context window\n",
    "    top=10,                # number of keywords to extract\n",
    "    features=None          # custom features\n",
    ")\n",
    "\n",
    "keywords = custom_kw_extractor.extract_keywords(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef08ff0-c06e-4d72-a7e0-3d260c8303c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arXiv Abstract: Abstract:As large language models (LLMs) continue to advance, their capacity to function effectively across a diverse range of languages has shown marked improvement. Preliminary studies observe that the hidden activations of LLMs often resemble English, even when responding to non-English prompts. This has led to the widespread assumption that LLMs may \"think\" in English. However, more recent results showing strong multilingual performance, even surpassing English performance on specific tasks in other languages, challenge this view. In this work, we find that LLMs progressively develop a core language-agnostic parameter space-a remarkably small subset of parameters whose deactivation results in significant performance degradation across all languages. This compact yet critical set of parameters underlies the model's ability to generalize beyond individual languages, supporting the emergence of abstract thought that is not tied to any specific linguistic system. Specifically, we identify language-related neurons-those are consistently activated during the processing of particular languages, and categorize them as either shared (active across multiple languages) or exclusive (specific to one). As LLMs undergo continued development over time, we observe a marked increase in both the proportion and functional importance of shared neurons, while exclusive neurons progressively diminish in influence. These shared neurons constitute the backbone of the core language-agnostic parameter space, supporting the emergence of abstract thought. Motivated by these insights, we propose neuron-specific training strategies tailored to LLMs' language-agnostic levels at different development stages. Experiments across diverse LLM families support our approach.\n",
      "PubMed Abstract: Objectives:\n",
      "        \n",
      "      \n",
      "      This article provides practical guidance on developing a comprehensible abstract, including those required for funding applications, conferences, and publication. In addition, we discuss and demonstrate the practicalities of editing and revising an abstract for conference or peer review and identify emerging formats that may be more relevant to nurses and researchers.\n",
      "    \n",
      "\n",
      "\n",
      "          Data sources:\n",
      "        \n",
      "      \n",
      "      This article has been informed by literature and the coauthors' respective experiences of preparing and reviewing abstracts for publication and conference presentation.\n",
      "    \n",
      "\n",
      "\n",
      "          Conclusion:\n",
      "        \n",
      "      \n",
      "      Abstracts are a valuable tool to communicate the most important elements of the methods and results of a research project for a conference, manuscript, or even a research funding application. However, abstracts may often be an overlooked part of the dissemination process. An abstract determines whether or not a piece of research is relevant for presentation at a conference or valuable enough to be considered for peer review and subsequent publication. A strong and clearly written abstract positively predisposes reviewers of grant applications.\n",
      "    \n",
      "\n",
      "\n",
      "          Implications for nursing practice:\n",
      "        \n",
      "      \n",
      "      Writing an abstract is arguably the most challenging component of academic writing, summarizing the results of a substantive research project in three to five sentences and positioning them concisely within the background and implications for future practice, policy, and research. A well-written abstract is clear, concise, and critical and requires time and revision to ensure success.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Example: Fetching an abstract from arXiv\n",
    "arxiv_url = \"https://arxiv.org/abs/2506.09890\"\n",
    "response = requests.get(arxiv_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "arxiv_abstract = soup.find('blockquote', class_='abstract').text.strip()\n",
    "\n",
    "# Example: Fetching an abstract from PubMed\n",
    "pubmed_url = \"https://pubmed.ncbi.nlm.nih.gov/36841679/\"\n",
    "response = requests.get(pubmed_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "pubmed_abstract = soup.find('div', class_='abstract-content selected').text.strip()\n",
    "\n",
    "print(\"arXiv Abstract:\", arxiv_abstract)\n",
    "print(\"PubMed Abstract:\", pubmed_abstract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0925fd7-b6cc-4b61-8ba9-b9c2facb35c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arXiv Keywords: [('shown marked improvement', 0.027418246957966005), ('continue to advance', 0.034322263132554535), ('capacity to function', 0.04719670093714441), ('function effectively', 0.04719670093714441), ('English', 0.08363930797155851), ('LLMs', 0.08377904615128112), ('languages', 0.09272405477267902), ('large language models', 0.10046793904076018), ('marked improvement', 0.11280050632892082), ('large language', 0.13392780759498793), ('shown marked', 0.13395929957107514), ('resemble English', 0.13806274688144946), ('diverse range', 0.1443949274915849), ('Abstract', 0.1514080174707939), ('English performance', 0.15732364620272973), ('surpassing English performance', 0.15801735680293902), ('core language-agnostic parameter', 0.17633765150404593), ('supporting the emergence', 0.17885190632522363), ('abstract thought', 0.17904928173420714), ('language-agnostic', 0.1795002112592393)]\n",
      "PubMed Keywords: [('including those required', 0.032356472395338315), ('practical guidance', 0.03547439826567785), ('guidance on developing', 0.03547439826567785), ('developing a comprehensible', 0.03547439826567785), ('abstract', 0.04784482967749958), ('comprehensible abstract', 0.056115865560431605), ('research funding application', 0.06299068219751633), ('conference', 0.06742600704538468), ('research', 0.0792589896891825), ('abstracts', 0.09568965935499917), ('peer review', 0.11058818810900031), ('publication', 0.11984747135238662), ('research project', 0.1219677080302777), ('funding applications', 0.12720942489401246), ('article provides practical', 0.12790000923571695), ('identify emerging formats', 0.14581199276465723), ('required for funding', 0.14613478091244872), ('conference presentation', 0.14887188876236027), ('article', 0.15206107953118572), ('Objectives', 0.15385593405825818)]\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "\n",
    "# Initialize yake keyword extractor\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "\n",
    "# Extract keywords from arXiv abstract\n",
    "arxiv_keywords = kw_extractor.extract_keywords(arxiv_abstract)\n",
    "print(\"arXiv Keywords:\", arxiv_keywords)\n",
    "\n",
    "# Extract keywords from PubMed abstract\n",
    "pubmed_keywords = kw_extractor.extract_keywords(pubmed_abstract)\n",
    "print(\"PubMed Keywords:\", pubmed_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff72dd0-95be-4a6d-b026-743189760125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Words in Descending order:\n",
      "shown marked improvement (0.0274)\n",
      "continue to advance (0.0343)\n",
      "capacity to function (0.0472)\n",
      "function effectively (0.0472)\n",
      "English (0.0836)\n",
      "LLMs (0.0838)\n",
      "languages (0.0927)\n",
      "large language models (0.1005)\n",
      "marked improvement (0.1128)\n",
      "large language (0.1339)\n",
      "shown marked (0.1340)\n",
      "resemble English (0.1381)\n",
      "diverse range (0.1444)\n",
      "Abstract (0.1514)\n",
      "English performance (0.1573)\n",
      "surpassing English performance (0.1580)\n",
      "core language-agnostic parameter (0.1763)\n",
      "supporting the emergence (0.1789)\n",
      "abstract thought (0.1790)\n",
      "language-agnostic (0.1795)\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords\n",
    "keywords = kw_extractor.extract_keywords(arxiv_abstract)\n",
    "\n",
    "# Sort by score\n",
    "sorted_keywords = sorted(keywords, key=lambda x: x[1])\n",
    "\n",
    "print(\"Key Words in Descending order:\")\n",
    "# Print keywords in descending order\n",
    "for kw, score in sorted_keywords:\n",
    "    print(f\"{kw} ({score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6fe69ac-7079-4ae8-8e2d-28e4f93c27e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Abstract**:As ****large language** models** (**LLMs**) **continue to advance**, their **capacity to function** effectively across a **diverse range** of **languages** has **shown **marked improvement****. Preliminary studies observe that the hidden activations of **LLMs** often resemble **English**, even when responding to non-**English** prompts. This has led to the widespread assumption that **LLMs** may \"think\" in **English**. However, more recent results showing strong multilingual performance, even surpassing **English** performance on specific tasks in other **languages**, challenge this view. In this work, we find that **LLMs** progressively develop a **core **language-agnostic** parameter** space-a remarkably small subset of parameters whose deactivation results in significant performance degradation across all **languages**. This compact yet critical set of parameters underlies the model's ability to generalize beyond individual **languages**, **supporting the emergence** of **abstract thought** that is not tied to any specific linguistic system. Specifically, we identify language-related neurons-those are consistently activated during the processing of particular **languages**, and categorize them as either shared (active across multiple **languages**) or exclusive (specific to one). As **LLMs** undergo continued development over time, we observe a marked increase in both the proportion and functional importance of shared neurons, while exclusive neurons progressively diminish in influence. These shared neurons constitute the backbone of the **core **language-agnostic** parameter** space, **supporting the emergence** of **abstract thought**. Motivated by these insights, we propose neuron-specific training strategies tailored to **LLMs**' **language-agnostic** levels at different development stages. Experiments across diverse LLM families support our approach.\n"
     ]
    }
   ],
   "source": [
    "# compare to the text\n",
    "text = arxiv_abstract\n",
    "keywords = [kw for kw, score in kw_extractor.extract_keywords(text)]\n",
    "\n",
    "highlighted_text = text\n",
    "for kw in keywords:\n",
    "    highlighted_text = highlighted_text.replace(kw, f\"**{kw}**\")\n",
    "\n",
    "print(highlighted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a11324c-6e21-44c5-9c04-6e999692c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated information grows (0.0094)\n",
      "large collections turns (0.0285)\n",
      "information grows (0.0410)\n",
      "reading and summarizing (0.0410)\n",
      "amount of generated (0.0481)\n",
      "generated information (0.0481)\n",
      "collections turns (0.0481)\n",
      "challenging task (0.0931)\n",
      "YAKE (0.1035)\n",
      "text (0.1090)\n"
     ]
    }
   ],
   "source": [
    "# Using Yake Paper Abstract as example to run parameters\n",
    "text = \"As the amount of generated information grows, reading and summarizing texts of large collections turns into a challenging task. Many documents do not come with descriptive terms, thus requiring humans to generate keywords on-the-fly. The need to automate this kind of task demands the development of keyword extraction systems with the ability to automatically identify keywords within the text. One approach is to resort to machine-learning algorithms. These, however, depend on large annotated text corpora, which are not always available. An alternative solution is to consider an unsupervised approach. In this article, we describe YAKE!, a light-weight unsupervised automatic keyword extraction method which rests on statistical text features extracted from single documents to select the most relevant keywords of a text. Our system does not need to be trained on a particular set of documents, nor does it depend on dictionaries, external corpora, text size, language, or domain. To demonstrate the merits and significance of YAKE!, we compare it against ten state-of-the-art unsupervised approaches and one supervised method. Experimental results carried out on top of twenty datasets show that YAKE! significantly outperforms other unsupervised methods on texts of different sizes, languages, and domains.\"\n",
    "\n",
    "# YAKE! with adjustable parameters usage\n",
    "kw_extractor = yake.KeywordExtractor(\n",
    "    lan=\"en\",           # Language of the text\n",
    "    n=3,                # max_ngram_size: consider unigrams, bigrams, trigrams\n",
    "    dedupLim=0.9,       # deduplication threshold: remove very similar keywords\n",
    "    top=10,             # num_keywords: number of keywords to extract\n",
    "    features=None       # default features (you can modify if needed)\n",
    ")\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "\n",
    "# Print keywords and scores\n",
    "for kw, score in keywords:\n",
    "    print(f\"{kw} ({score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c28154d5-3152-437a-9600-b6db1313c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of generated information grows (0.0022)\n",
      "generated information grows (0.0094)\n",
      "amount of generated information (0.0111)\n",
      "reading and summarizing texts (0.0273)\n",
      "large collections turns (0.0285)\n"
     ]
    }
   ],
   "source": [
    "# Using Yake Paper Abstract as example to run different parameters\n",
    "text = \"As the amount of generated information grows, reading and summarizing texts of large collections turns into a challenging task. Many documents do not come with descriptive terms, thus requiring humans to generate keywords on-the-fly. The need to automate this kind of task demands the development of keyword extraction systems with the ability to automatically identify keywords within the text. One approach is to resort to machine-learning algorithms. These, however, depend on large annotated text corpora, which are not always available. An alternative solution is to consider an unsupervised approach. In this article, we describe YAKE!, a light-weight unsupervised automatic keyword extraction method which rests on statistical text features extracted from single documents to select the most relevant keywords of a text. Our system does not need to be trained on a particular set of documents, nor does it depend on dictionaries, external corpora, text size, language, or domain. To demonstrate the merits and significance of YAKE!, we compare it against ten state-of-the-art unsupervised approaches and one supervised method. Experimental results carried out on top of twenty datasets show that YAKE! significantly outperforms other unsupervised methods on texts of different sizes, languages, and domains.\"\n",
    "\n",
    "# YAKE! with adjustable parameters usage\n",
    "kw_extractor = yake.KeywordExtractor(\n",
    "    lan=\"en\",           # Language of the text\n",
    "    n=5,                # max_ngram_size: consider unigrams, bigrams, trigrams\n",
    "    dedupLim=0.5,       # deduplication threshold: remove very similar keywords\n",
    "    top=5,             # num_keywords: number of keywords to extract\n",
    "    features=None       # default features (you can modify if needed)\n",
    ")\n",
    "\n",
    "# Extract keywords\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "\n",
    "# Print keywords and scores\n",
    "for kw, score in keywords:\n",
    "    print(f\"{kw} ({score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6898b-77a2-492c-a140-9ba93c408860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
